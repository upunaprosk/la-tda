{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Notebook for ripser features calculation.\n",
        "Based on [the code](https://github.com/danchern97/tda4atd/blob/main/features_calculation_ripser_and_templates.ipynb). "
      ],
      "metadata": {
        "id": "knFMzZEuK1mO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDX475rlZirn"
      },
      "outputs": [],
      "source": [
        "# *GPU is required for ripserplusplus\n",
        "# !pip install transformers\n",
        "# !pip install ripserplusplus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tlym489Hivt_"
      },
      "outputs": [],
      "source": [
        "subset = \"test_sub\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIndHZtZixSX"
      },
      "outputs": [],
      "source": [
        "model_path = \"./la-tda-models/bert-base-cased-en-cola_32_3e-05_lr_0.01_decay_balanced/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J26OfHHselHg"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
        "from multiprocessing import Process, Queue, Pool\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import json\n",
        "import gzip\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ukcc_g8aJSR0"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3ChEFe7eHSK"
      },
      "outputs": [],
      "source": [
        "import ripserplusplus as rpp\n",
        "# import numpy as np\n",
        "# from tqdm import tqdm\n",
        "import time\n",
        "# from utils import cutoff_matrix\n",
        "\n",
        "###################################\n",
        "# RIPSER FEATURE CALCULATION FORMAT\n",
        "###################################\n",
        "# Format: \"h{dim}\\_{type}\\_{args}\"\n",
        "\n",
        "# Dimension: 0, 1, etc.; homology dimension\n",
        "\n",
        "# Types: \n",
        "    \n",
        "#     1. s: sum of lengths; example: \"h1_s\".\n",
        "#     2. m: mean of lengths; example: \"h1_m\"\n",
        "#     3. v: variance of lengths; example \"h1_v\"\n",
        "#     4. e: entropy of persistence diagram.\n",
        "#     2. n: number of barcodes with time of birth/death more/less then threshold.\n",
        "#         2.1. b/d: birth or death\n",
        "#         2.2. m/l: more or less than threshold\n",
        "#         2.2. t: threshold value\n",
        "#        example: \"h0_n_d_m_t0.5\", \"h1_n_b_l_t0.75\"\n",
        "#     3. t: time of birth/death of the longest barcode (not incl. inf).\n",
        "#         3.1. b/d: birth of death\n",
        "#             example: \"h0_t_d\", \"h1_t_b\"\n",
        "\n",
        "####################################\n",
        "\n",
        "def barcode_pop_inf(barcode):\n",
        "    \"\"\"Delete all infinite barcodes\"\"\"\n",
        "    for dim in barcode:\n",
        "        if len(barcode[dim]):\n",
        "            barcode[dim] = barcode[dim][barcode[dim]['death'] != np.inf]\n",
        "    return barcode\n",
        "\n",
        "def barcode_number(barcode, dim=0, bd='death', ml='m', t=0.5):\n",
        "    \"\"\"Calculate number of barcodes in h{dim} with time of birth/death more/less then threshold\"\"\"\n",
        "    if len(barcode[dim]):\n",
        "        if ml == 'm':\n",
        "            return np.sum(barcode[dim][bd] >= t)\n",
        "        elif ml == 'l':\n",
        "            return np.sum(barcode[dim][bd] <= t)\n",
        "        else:\n",
        "            raise Exception(\"Wrong more/less type in barcode_number calculation\")\n",
        "    else:\n",
        "        return 0.0\n",
        "        \n",
        "def barcode_time(barcode, dim=0, bd='birth'):\n",
        "    \"\"\"Calculate time of birth/death in h{dim} of longest barcode\"\"\"\n",
        "    if len(barcode[dim]):\n",
        "        max_len_idx = np.argmax(barcode[dim]['death'] - barcode[dim]['birth'])\n",
        "        return barcode[dim][bd][max_len_idx]\n",
        "    else:\n",
        "        return 0.0\n",
        "    \n",
        "def barcode_number_of_barcodes(barcode, dim=0):\n",
        "    return len(barcode[dim])\n",
        "\n",
        "def barcode_entropy(barcode, dim=0):\n",
        "    if len(barcode[dim]):\n",
        "        lengths = barcode[dim]['death'] - barcode[dim]['birth']\n",
        "        lengths /= np.sum(lengths)\n",
        "        return -np.sum(lengths*np.log(lengths))\n",
        "    else:\n",
        "        return 0.0\n",
        "    \n",
        "\n",
        "# def barcode_lengths(barcode, dim=0):\n",
        "#     return barcode[dim]['death'] - barcode[dim]['birth']\n",
        "\n",
        "def barcode_sum(barcode, dim=0):\n",
        "    \"\"\"Calculate sum of lengths of barcodes in h{dim}\"\"\"\n",
        "    if len(barcode[dim]):\n",
        "        return np.sum(barcode[dim]['death'] - barcode[dim]['birth'])\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def barcode_mean(barcode, dim=0):\n",
        "    \"\"\"Calculate mean of lengths of barcodes in h{dim}\"\"\"\n",
        "    if len(barcode[dim]):\n",
        "        return np.mean(barcode[dim]['death'] - barcode[dim]['birth'])\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def barcode_std(barcode, dim=0):\n",
        "    \"\"\"Calculate std of lengths of barcodes in h{dim}\"\"\"\n",
        "    if len(barcode[dim]):\n",
        "        return np.std(barcode[dim]['death'] - barcode[dim]['birth'])\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def count_ripser_features(barcodes, feature_list=['h0_m']):\n",
        "    \"\"\"Calculate all provided ripser features\"\"\"\n",
        "    # first pop all infs from barcodes\n",
        "    barcodes = [barcode_pop_inf(barcode) for barcode in barcodes]\n",
        "    # calculate features\n",
        "    features = []\n",
        "    for feature in feature_list:\n",
        "        feature = feature.split('_')\n",
        "        # dimension, feature type and args\n",
        "        dim, ftype, fargs = int(feature[0][1:]), feature[1], feature[2:]\n",
        "        if ftype == 's':\n",
        "            feat = [barcode_sum(barcode, dim) for barcode in barcodes]\n",
        "        elif ftype == 'm':\n",
        "            feat = [barcode_mean(barcode, dim) for barcode in barcodes]\n",
        "        elif ftype == 'v':\n",
        "            feat = [barcode_std(barcode, dim) for barcode in barcodes]\n",
        "        elif ftype == 'n':\n",
        "            bd, ml, t = fargs[0], fargs[1], float(fargs[2][1:])\n",
        "            if bd == 'b':\n",
        "                bd = 'birth'\n",
        "            elif bd == 'd':\n",
        "                bd = 'death'\n",
        "            feat = [barcode_number(barcode, dim, bd, ml, t) for barcode in barcodes]\n",
        "        elif ftype == 't':\n",
        "            bd = fargs[0]\n",
        "            if bd == 'b':\n",
        "                bd = 'birth'\n",
        "            elif bd == 'd':\n",
        "                bd = 'death'\n",
        "            feat = [barcode_time(barcode, dim, bd) for barcode in barcodes]\n",
        "        elif ftype == 'nb':\n",
        "            feat = [barcode_number_of_barcodes(barcode, dim) for barcode in barcodes]\n",
        "        elif ftype == 'e':\n",
        "            feat = [barcode_entropy(barcode, dim) for barcode in barcodes]\n",
        "        features.append(feat) \n",
        "    return np.swapaxes(np.array(features), 0, 1) # samples X n_features\n",
        "\n",
        "def matrix_to_ripser(matrix, ntokens, lower_bound=0.0):\n",
        "    \"\"\"Convert matrix to appropriate ripser++ format\"\"\"\n",
        "    matrix = cutoff_matrix(matrix, ntokens)\n",
        "    matrix = (matrix > lower_bound).astype(np.int) * matrix\n",
        "    matrix = 1.0 - matrix\n",
        "    matrix -= np.diag(np.diag(matrix)) # 0 on diagonal\n",
        "    matrix = np.minimum(matrix.T, matrix) # symmetrical, edge emerges if at least one direction is working\n",
        "    return matrix\n",
        "\n",
        "def run_ripser_on_matrix(matrix, dim):\n",
        "    barcode = rpp.run(f\"--format distance --dim {dim}\", data=matrix)\n",
        "    return barcode\n",
        "\n",
        "def get_barcodes(matricies, ntokens_array, dim=1, lower_bound=0.0, layer_head=(0, 0)):\n",
        "    \"\"\"Get barcodes from matrix\"\"\"\n",
        "    barcodes = []\n",
        "    layer, head = layer_head\n",
        "    \n",
        "    for i, matrix in enumerate(matricies):\n",
        "#         with open(\"log.txt\", 'w') as fp: # logging into file\n",
        "#             fp.write(str(layer) + \"_\" + str(head) + \"_\" + str(i) + \"\\n\")\n",
        "        matrix = matrix_to_ripser(matrix, ntokens_array[i], lower_bound)\n",
        "        barcode = run_ripser_on_matrix(matrix, dim)\n",
        "        barcodes.append(barcode)\n",
        "    return barcodes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug35QOe2Sq57"
      },
      "outputs": [],
      "source": [
        "def cutoff_matrix(matrix, ntokens):\n",
        "    \"\"\"Return normalized submatrix of first n_tokens\"\"\"\n",
        "    matrix = matrix[:ntokens, :ntokens]\n",
        "    matrix /= matrix.sum(axis=1, keepdims=True)\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9W6bsCvelH2"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOlJZTNV9Nzs"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "max_tokens_amount  = 64\n",
        "MAX_LEN = max_tokens_amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5yrTzGPL3oe",
        "outputId": "0bcfca3d-093f-481b-8157-5044505a3138"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./la-tda-models/bert-base-cased-en-cola_32_3e-05_lr_0.01_decay_balanced/attentions/test_sub',\n",
              " './la-tda-models/bert-base-cased-en-cola_32_3e-05_lr_0.01_decay_balanced/barcodes/test_sub')"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "r_file = model_path + 'attentions/' + subset\n",
        "barcodes_file = model_path + 'barcodes/' +subset\n",
        "r_file, barcodes_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEH9CostHoCa"
      },
      "outputs": [],
      "source": [
        "def get_token_length(batch_texts):\n",
        "    inputs = tokenizer.batch_encode_plus(batch_texts,\n",
        "       return_tensors='pt',\n",
        "       add_special_tokens=True,\n",
        "       max_length=64,             # Max length to truncate/pad\n",
        "       pad_to_max_length=True,         # Pad sentence to max length\n",
        "       truncation=True\n",
        "    )\n",
        "    inputs = inputs['input_ids'].numpy()\n",
        "    n_tokens = []\n",
        "    indexes = np.argwhere(inputs == tokenizer.pad_token_id)\n",
        "    for i in range(inputs.shape[0]):\n",
        "        ids = indexes[(indexes == i)[:, 0]]\n",
        "        if not len(ids):\n",
        "            n_tokens.append(MAX_LEN)\n",
        "        else:\n",
        "            n_tokens.append(ids[0, 1])\n",
        "    return n_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vkE2Go9elH4"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"./data/en-cola/\" + subset + '.csv')\n",
        "data['tokenizer_length'] = get_token_length(list(data['sentence'].values))\n",
        "sentences = data['sentence']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlRFDFWKMovv"
      },
      "outputs": [],
      "source": [
        "batch_size = 10 # batch size\n",
        "number_of_batches = ceil(len(data['sentence']) / batch_size)\n",
        "DUMP_SIZE = 100 # number of batches to be dumped\n",
        "batched_sentences = np.array_split(data['sentence'].values, number_of_batches)\n",
        "number_of_files = ceil(number_of_batches / DUMP_SIZE)\n",
        "adj_matricies = []\n",
        "adj_filenames = []\n",
        "assert number_of_batches == len(batched_sentences) # sanity check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG3Sb1hrelI3"
      },
      "source": [
        "# Ripser features calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd9H6J3pelI8"
      },
      "source": [
        "Format: \"h{dim}\\_{type}\\_{args}\"\n",
        "\n",
        "Dimension: 0, 1, etc.; homology dimension\n",
        "\n",
        "Types: \n",
        "    \n",
        "    1. s: sum of lengths; example: \"h1_s\".\n",
        "    2. m: mean of lengths; example: \"h1_m\"\n",
        "    3. v: variance of lengths; example \"h1_v\"\n",
        "    4. n: number of barcodes with time of birth/death more/less then threshold.\n",
        "        4.1. b/d: birth or death\n",
        "        4.2. m/l: more or less than threshold\n",
        "        4.2. t: threshold value\n",
        "       example: \"h0_n_d_m_t0.5\", \"h1_n_b_l_t0.75\"\n",
        "    5. t: time of birth/death of the longest barcode (not incl. inf).\n",
        "        3.1. b/d: birth of death\n",
        "        example: \"h0_t_d\", \"h1_t_b\"\n",
        "    6. nb: number of barcodes in dim\n",
        "       example: h0_nb\n",
        "    7. e: entropy; example: \"h1_e\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmh6mwfeelI_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def order_files(path, subset):\n",
        "    files_path = Path(path)\n",
        "    files = list(filter(lambda y: (y.is_file() and subset in str(y)), files_path.iterdir()))\n",
        "    files = [str(_) for _ in files]\n",
        "    files = sorted(files, key=lambda x: int(x.split('_')[-1].split('of')[0][4:].strip()))\n",
        "    return files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir=model_path\n",
        "attn_dir = model_path + \"/attentions/\"\n",
        "adj_filenames = order_files(path=attn_dir, subset=subset)"
      ],
      "metadata": {
        "id": "dfn_kSMbcXha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foy8xNBlUPwk",
        "outputId": "d985503e-6cd6-4d27-d1c2-56a8b0e257a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./la-tda-models/bert-base-cased-en-cola_32_3e-05_lr_0.01_decay_balanced/attentions/test_sub_part1of1.npy.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EfxxWr3elJB"
      },
      "outputs": [],
      "source": [
        "dim = 1\n",
        "lower_bound = 1e-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeeWTxh2elJC"
      },
      "source": [
        "## Barcodes calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ_WQHXUelJE"
      },
      "outputs": [],
      "source": [
        "def subprocess_wrap(queue, function, args):\n",
        "    queue.put(function(*args))\n",
        "    queue.close()\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpH0u_v8elJF"
      },
      "outputs": [],
      "source": [
        "def get_only_barcodes(adj_matricies, ntokens_array, dim, lower_bound, verbose=False):\n",
        "    \"\"\"Get barcodes from adj matricies for each layer, head\"\"\"\n",
        "    barcodes = {}\n",
        "    layers, heads = range(adj_matricies.shape[1]), range(adj_matricies.shape[2])\n",
        "    iter = itertools.product(layers, heads)\n",
        "    if verbose:\n",
        "        iter = tqdm(iter, 'Layer, Head', leave=False)\n",
        "    for (layer, head) in iter:\n",
        "        matricies = adj_matricies[:, layer, head, :, :]\n",
        "        barcodes[(layer, head)] = get_barcodes(matricies, ntokens_array, dim, lower_bound, (layer, head))\n",
        "    return barcodes\n",
        "\n",
        "def format_barcodes(barcodes):\n",
        "    \"\"\"Reformat barcodes to json-compatible format\"\"\"\n",
        "    return [{d: b[d].tolist() for d in b} for b in barcodes]\n",
        "\n",
        "def save_barcodes(barcodes, filename):\n",
        "    \"\"\"Save barcodes to file\"\"\"\n",
        "    formatted_barcodes = defaultdict(dict)\n",
        "    for layer, head in barcodes:\n",
        "        formatted_barcodes[layer][head] = format_barcodes(barcodes[(layer, head)])\n",
        "    json.dump(formatted_barcodes, open(filename, 'w'))\n",
        "    \n",
        "def unite_barcodes(barcodes, barcodes_part):\n",
        "    \"\"\"Unite 2 barcodes\"\"\"\n",
        "    for (layer, head) in barcodes_part:\n",
        "        barcodes[(layer, head)].extend(barcodes_part[(layer, head)])\n",
        "    return barcodes\n",
        "\n",
        "def split_matricies_and_lengths(adj_matricies, ntokens, number_of_splits):\n",
        "    splitted_ids = np.array_split(np.arange(ntokens.shape[0]), number_of_splits) \n",
        "    splitted = [(adj_matricies[ids], ntokens[ids]) for ids in splitted_ids]\n",
        "    return splitted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoqaIrgCTyao"
      },
      "outputs": [],
      "source": [
        "barcodes_dir = model_path + 'barcodes/'\n",
        "!mkdir $barcodes_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM8pT0WJelJH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "queue = Queue()\n",
        "number_of_splits = 4\n",
        "run_in_parallel = False\n",
        "\n",
        "for i, filename in enumerate(tqdm(adj_filenames, desc='Barcodes calculation')):\n",
        "    part = filename.split('_')[-1].split('.')[0]\n",
        "    if os.path.isfile(barcodes_file + '_' + part + '.json'):\n",
        "        print(\"file already exists\")\n",
        "        print(\"passing\", barcodes_file + '_' + part + '.json')\n",
        "        continue\n",
        "\n",
        "    barcodes = defaultdict(list)\n",
        "    with gzip.GzipFile(filename, 'rb') as f:\n",
        "        adj_matricies = np.load(f, allow_pickle=True)\n",
        "        ntokens = ntokens_array[i*batch_size*DUMP_SIZE : (i+1)*batch_size*DUMP_SIZE]\n",
        "    if not run_in_parallel:\n",
        "        barcodes = get_only_barcodes(adj_matricies, ntokens, dim, lower_bound, verbose=True)\n",
        "    else:\n",
        "        splitted = split_matricies_and_lengths(adj_matricies, ntokens, number_of_splits)\n",
        "        for matricies, ntokens in tqdm(splitted, leave=False):\n",
        "            p = Process(\n",
        "                target=subprocess_wrap,\n",
        "                args=(\n",
        "                    queue,\n",
        "                    get_only_barcodes,\n",
        "                    (matricies, ntokens, dim, lower_bound)\n",
        "                )\n",
        "            ) \n",
        "            p.start()\n",
        "            barcodes_part = queue.get() # block until putted and get barcodes from the queue\n",
        "            p.join() # release resources\n",
        "            p.close() # releasing resources of ripser\n",
        "            barcodes = unite_barcodes(barcodes, barcodes_part)\n",
        "\n",
        "    \n",
        "    save_barcodes(barcodes, barcodes_file + '_' + part + '.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "7xcIXaP0qYl8",
        "outputId": "9479660d-876f-4159-81ce-749d92d7ba3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./la-tda-models/bert-base-cased-en-cola_32_3e-05_lr_0.01_decay_balanced//features/barcodes/test_sub'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "barcodes_file=f\"{model_path}/features/barcodes/{subset}\"\n",
        "barcodes_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3MnQ0fQelJJ"
      },
      "source": [
        "## Barcodes' ripser features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7IW7Y5Hq58u"
      },
      "outputs": [],
      "source": [
        "barcodes_file_dir = input_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvKj5rJfelJL"
      },
      "outputs": [],
      "source": [
        "ripser_features=[\n",
        "    'h0_s', \n",
        "    'h0_e',\n",
        "    'h0_t_d', \n",
        "    'h0_n_d_m_t0.75',\n",
        "    'h0_n_d_m_t0.5',\n",
        "    'h0_n_d_l_t0.25',\n",
        "    'h1_t_b',\n",
        "    'h1_n_b_m_t0.25',\n",
        "    'h1_n_b_l_t0.95', \n",
        "    'h1_n_b_l_t0.70',  \n",
        "    'h1_s',\n",
        "    'h1_e',\n",
        "    'h1_v',\n",
        "    'h1_nb'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD-L4b1WelJM",
        "outputId": "d9ab5d9a-9e43-4b72-cd62-b56900c26fe9",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./la-tda-models/bert-base-cased-en-cola_32_3e-05_lr_0.01_decay_balanced//barcodes/test_sub_part1of1.json']"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "json_filenames = [\n",
        "    output_dir + '/barcodes/' + filename \n",
        "    for filename in os.listdir(model_path + '/barcodes/') if r_file.split('/')[-1] in filename.split('_part')[0]\n",
        "\n",
        "]\n",
        "json_filenames = sorted(json_filenames, key = lambda x: int(x.split('_')[-1].split('of')[0][4:].strip())) \n",
        "json_filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTq54Bc4elJO"
      },
      "outputs": [],
      "source": [
        "def reformat_barcodes(barcodes):\n",
        "    \"\"\"Return barcodes to their original format\"\"\"\n",
        "    formatted_barcodes = []\n",
        "    for barcode in barcodes:\n",
        "        formatted_barcode = {}\n",
        "        for dim in barcode:\n",
        "            formatted_barcode[int(dim)] = np.asarray(\n",
        "                [(b, d) for b,d in barcode[dim]], dtype=[('birth', '<f4'), ('death', '<f4')]\n",
        "            )\n",
        "        formatted_barcodes.append(formatted_barcode)\n",
        "    return formatted_barcodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVF1l3djelJQ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "features_array = []\n",
        "\n",
        "for filename in tqdm(json_filenames, desc='Computing ripser++'):\n",
        "    barcodes = json.load(open(filename))\n",
        "    print(f\"Barcodes loaded from: {filename}\", flush=True)\n",
        "    features_part = []\n",
        "    for layer in barcodes:\n",
        "        features_layer = []\n",
        "        for head in barcodes[layer]:\n",
        "            ref_barcodes = reformat_barcodes(barcodes[layer][head])\n",
        "            features = count_ripser_features(ref_barcodes, ripser_features)\n",
        "            features_layer.append(features)\n",
        "        features_part.append(features_layer)\n",
        "    features_array.append(np.asarray(features_part))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j94XU9UmelJT",
        "outputId": "2949c5c5-6bad-4483-aac9-3a4a46637671"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 12, 533, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "features = np.concatenate(features_array, axis=2)\n",
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "DBNvwbG-rsyM",
        "outputId": "d5dc0c47-52ca-4a47-a22a-67b251caed39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./la-tda-models/bert-base-cased-en-cola_32_3e-05_lr_0.01_decay_balanced/features/test_sub_ripser.npy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "ripser_file=f\"{model_path}features/{subset}_ripser.npy\"\n",
        "ripser_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4jgxv88FTUC"
      },
      "outputs": [],
      "source": [
        "%cd $model_path\n",
        "!mkdir features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDgyEX-relJU"
      },
      "outputs": [],
      "source": [
        "np.save(ripser_file, features)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}